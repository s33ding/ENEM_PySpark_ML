{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import pyspark \n",
    "import os \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col, udf, rank, asc, sum as spark_sum\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------------------------+------------------+------------+----------------------------+\n",
      "|NOTA_CH_CIENCIAS_HUMANAS|NOTA_LC_LINGUAGENS_E_CODIGOS|NOTA_MT_MATEMATICA|NOTA_REDACAO|NOTA_CN_CIENCIAS_DA_NATUREZA|\n",
      "+------------------------+----------------------------+------------------+------------+----------------------------+\n",
      "|                   478.4|                       426.8|             351.2|       380.0|                       411.3|\n",
      "|                   459.3|                       571.7|             467.0|       900.0|                       440.0|\n",
      "|                   435.7|                       568.2|             414.7|       960.0|                       607.1|\n",
      "+------------------------+----------------------------+------------------+------------+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start a Spark session\n",
    "spark = SparkSession.builder.appName(\"s33ding\").getOrCreate()\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = spark.read.parquet(\"dataset/enem.parquet\")\n",
    "# Select the relevant columns\n",
    "selected_cols = [\"NOTA_CH_CIENCIAS_HUMANAS\", \"NOTA_LC_LINGUAGENS_E_CODIGOS\", \"NOTA_MT_MATEMATICA\", \"NOTA_REDACAO\",\"NOTA_CN_CIENCIAS_DA_NATUREZA\"]\n",
    "df_selected = df.select(selected_cols)\n",
    "df_selected.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/14 01:07:19 WARN Instrumentation: [045749b4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_data, validation_data, test_data = df_selected.randomSplit([0.6, 0.2, 0.2], seed=42)\n",
    "\n",
    "# Prepare the feature vector and the target column for the training, validation, and testing sets\n",
    "assembler = VectorAssembler(inputCols=[\"NOTA_LC_LINGUAGENS_E_CODIGOS\", \"NOTA_MT_MATEMATICA\", \"NOTA_REDACAO\"], outputCol=\"features\")\n",
    "\n",
    "# Transform the training data and add a primary key column\n",
    "train_data = assembler.transform(train_data).select(\"features\", \"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "train_data = train_data.withColumn(\"pk\", monotonically_increasing_id())\n",
    "\n",
    "# Transform the validation data and add a primary key column\n",
    "validation_data = assembler.transform(validation_data).select(\"features\", \"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "validation_data = validation_data.withColumn(\"pk\", monotonically_increasing_id())\n",
    "\n",
    "# Transform the testing data and add a primary key column\n",
    "test_data = assembler.transform(test_data).select(\"features\", \"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "test_data = test_data.withColumn(\"pk\", monotonically_increasing_id())\n",
    "\n",
    "# Train the machine learning models using the training set\n",
    "# Linear Regression\n",
    "lr = LinearRegression(labelCol=\"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Decision Tree Regression\n",
    "dt = DecisionTreeRegressor(labelCol=\"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Random Forest Regression\n",
    "rf = RandomForestRegressor(labelCol=\"NOTA_CN_CIENCIAS_DA_NATUREZA\")\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions using the trained models on the validation set\n",
    "lr_predictions = lr_model.transform(validation_data)\n",
    "dt_predictions = dt_model.transform(validation_data)\n",
    "rf_predictions = rf_model.transform(validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+----------------------------+\n",
      "|            features|     lr_prediction|     dt_prediction|     rf_prediction|NOTA_CN_CIENCIAS_DA_NATUREZA|\n",
      "+--------------------+------------------+------------------+------------------+----------------------------+\n",
      "| [413.0,444.0,360.0]| 417.1890685808009| 423.1020666217345| 429.0939459227814|                       381.8|\n",
      "|[345.399993896484...| 381.6734296910864| 423.1020666217345| 425.0362786947635|                       381.4|\n",
      "|[326.700012207031...|387.33017447876017| 423.1020666217345| 433.6279647120011|                       434.2|\n",
      "|[385.200012207031...| 383.8776007102846| 423.1020666217345|424.60054080470434|                       448.3|\n",
      "|[334.600006103515...|408.02071087368336|436.36443385870047| 445.1555965113309|                       352.7|\n",
      "|[434.200012207031...|460.03156244267313|462.94221956370393| 454.7604784088786|                       422.4|\n",
      "|[498.0,458.299987...| 458.1325107026296|445.70663192703745| 446.9929979636636|                       506.3|\n",
      "|[389.700012207031...| 399.9150121036773|436.36443385870047| 433.6931080118094|                       485.7|\n",
      "|[351.700012207031...|397.55845524443976| 423.1020666217345| 426.2322224138894|                       398.2|\n",
      "|[336.399993896484...|363.59569507615885| 423.1020666217345|424.60054080470434|                       374.6|\n",
      "|[380.0,380.700012...|  382.703113180812| 423.1020666217345| 425.0362786947635|                       388.0|\n",
      "|[388.600006103515...|377.62238218860375| 423.1020666217345|424.60054080470434|                       400.8|\n",
      "|[486.600006103515...|447.56448500293044|445.70663192703745|446.60299582818544|                       366.3|\n",
      "|[551.299987792968...|509.29008186857817| 498.1876036476126|495.35725551398934|                       403.8|\n",
      "|[462.100006103515...| 415.8201373301765| 423.1020666217345| 431.8058612152257|                       397.6|\n",
      "|[463.399993896484...| 433.0063940222532|436.36443385870047| 436.0812709575087|                       357.3|\n",
      "|[426.200012207031...| 398.2217268769386| 423.1020666217345| 426.3091922491503|                       433.8|\n",
      "|[483.200012207031...| 440.4573760114724|445.70663192703745| 436.3737188262042|                       423.4|\n",
      "|[567.5,598.299987...| 518.2209898729677| 522.6047491154989| 512.8346545032776|                       504.0|\n",
      "|[332.700012207031...| 389.7541730562013|436.36443385870047|431.95150473805927|                       400.4|\n",
      "+--------------------+------------------+------------------+------------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create temporary views for the predictions\n",
    "lr_predictions.createOrReplaceTempView(\"lr_predictions\")\n",
    "dt_predictions.createOrReplaceTempView(\"dt_predictions\")\n",
    "rf_predictions.createOrReplaceTempView(\"rf_predictions\")\n",
    "\n",
    "# Join the predictions using the primary key (pk) column\n",
    "joined_predictions = spark.sql(\"\"\"\n",
    "    SELECT lr_predictions.features, lr_predictions.prediction AS lr_prediction,\n",
    "           dt_predictions.prediction AS dt_prediction, rf_predictions.prediction AS rf_prediction,\n",
    "           lr_predictions.NOTA_CN_CIENCIAS_DA_NATUREZA\n",
    "    FROM lr_predictions\n",
    "    JOIN dt_predictions ON lr_predictions.pk = dt_predictions.pk\n",
    "    JOIN rf_predictions ON lr_predictions.pk = rf_predictions.pk\n",
    "    ORDER BY lr_predictions.pk\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Get a sample from the joined_predictions DataFrame\n",
    "sample_joined_predictions = joined_predictions.sample(fraction=0.1, seed=42)\n",
    "\n",
    "# Save the sample as a Parquet file\n",
    "sample_joined_predictions.write.mode('overwrite').parquet('data_for_dashboards/models/joined_predictions.parquet')\n",
    "\n",
    "# Show the joined predictions\n",
    "joined_predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------+----+-----+\n",
      "|Model                         |Metric            |Type|Best |\n",
      "+------------------------------+------------------+----+-----+\n",
      "|Random Forest Regression - MAE|42.46582183771729 |MAE |true |\n",
      "|Linear Regression - MAE       |42.53800192500141 |MAE |false|\n",
      "|Decision Tree Regression - MAE|42.59457338590594 |MAE |false|\n",
      "|Random Forest Regression - MSE|2767.006748070056 |MSE |true |\n",
      "|Linear Regression - MSE       |2817.5776266367934|MSE |false|\n",
      "|Decision Tree Regression - MSE|2822.5567248988423|MSE |false|\n",
      "+------------------------------+------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"NOTA_CN_CIENCIAS_DA_NATUREZA\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate MSE for linear regression\n",
    "lr_mse = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"mse\"})\n",
    "\n",
    "# Calculate MSE for decision tree regression\n",
    "dt_mse = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"mse\"})\n",
    "\n",
    "# Calculate MSE for random forest regression\n",
    "rf_mse = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"mse\"})\n",
    "\n",
    "# Calculate MAE for linear regression\n",
    "lr_mae = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "# Calculate MAE for decision tree regression\n",
    "dt_mae = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "# Calculate MAE for random forest regression\n",
    "rf_mae = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "# Calculate MSE and MAE for each model\n",
    "metrics = [(\"Linear Regression - MSE\", lr_mse),\n",
    "           (\"Decision Tree Regression - MSE\", dt_mse),\n",
    "           (\"Random Forest Regression - MSE\", rf_mse),\n",
    "           (\"Linear Regression - MAE\", lr_mae),\n",
    "           (\"Decision Tree Regression - MAE\", dt_mae),\n",
    "           (\"Random Forest Regression - MAE\", rf_mae)]\n",
    "\n",
    "# Create the DataFrame with \"Type\" column\n",
    "df_comparing_models = spark.createDataFrame(metrics, [\"Model\", \"Metric\"]).withColumn(\"Type\", udf(lambda model: \"MSE\" if \"MSE\" in model else \"MAE\", StringType())(\"Model\"))\n",
    "\n",
    "# Create a window specification to partition by the type and order by the metric in ascending order\n",
    "window_spec = Window.partitionBy(\"Type\").orderBy(asc(\"Metric\"))\n",
    "\n",
    "# Add a \"Best\" column to determine the best model for each type\n",
    "df_comparing_models = df_comparing_models.withColumn(\"Best\", rank().over(window_spec) == 1)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_comparing_models.show(truncate=False)\n",
    "tmp = df_comparing_models.toPandas()\n",
    "tmp.to_parquet('data_for_dashboards/eda/models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to save the model\n",
    "model_path = \"models/nota_ch_ciencias_humanas/random_forest\"\n",
    "\n",
    "# Save the Linear Regression model\n",
    "rf_model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
