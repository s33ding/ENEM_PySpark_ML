Enem_2020_2021_anomalies Data Modeling Project with PySpark
Project Description
In this project, we leverage the capabilities of PySpark to prepare a model for estimating "Natural Sciences" scores and "Color and Race" variables. The dataset we're working with is the Enem_2020_2021_anomalies database, which can be downloaded from the following link: Enem_2020_2021_anomalies database.

PySpark, the Python library for Apache Spark, offers powerful functionalities for large-scale data processing, making it suitable for our data modeling tasks.

Project Tasks
Evaluate the quality of the database: Utilize PySpark's data manipulation capabilities to explore and understand the data types, detect possible outliers, identify missing values, and find inconsistent entries.

Data preparation: Correct variable types and handle other anomalies in the dataset using PySpark's robust data transformation functions.

Building Models: Impute missing values, handle outliers, and manage disparate values using PySpark's Machine Learning library (MLlib).

Model development: Develop three models for each variable - "Natural Sciences" scores and "Color and Race". This will result in a total of six (6) models. PySpark MLlib offers various algorithms for model development.

Model evaluation: Compare the models' performance for each variable to identify the best one. PySpark MLlib also provides tools for model evaluation.

Model application: Apply the best models to predict the variables using the ENEM_Score_Ciencia_Natureza and ENEM_Score_Cor_Raca files.

Report development: Develop a comprehensive report detailing your project, including the steps taken, challenges encountered, and results obtained.

Presentation preparation: Prepare a presentation summarizing the project, including its key aspects. Ensure it does not exceed 15 minutes.

These steps serve as general guidelines for the project. Depending on the specifics of the data and the objectives of the modeling task, additional steps may be necessary.
