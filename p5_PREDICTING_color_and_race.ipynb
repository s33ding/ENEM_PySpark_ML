{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import pyspark \n",
    "import os \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col, sum as spark_sum\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegressionModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark session\n",
    "spark = SparkSession.builder.appName(\"s33ding\").getOrCreate()\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = spark.read.csv(\"dataset/score_cn.csv\", sep=';',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: NOTA_CH_CIENCIAS_HUMANAS\n",
      "col: NOTA_LC_LINGUAGENS_E_CODIGOS\n",
      "col: NOTA_MT_MATEMATICA\n",
      "col: NOTA_REDACAO\n",
      "+------------------------+----------------------------+------------------+------------+\n",
      "|NOTA_CH_CIENCIAS_HUMANAS|NOTA_LC_LINGUAGENS_E_CODIGOS|NOTA_MT_MATEMATICA|NOTA_REDACAO|\n",
      "+------------------------+----------------------------+------------------+------------+\n",
      "|                   385.4|                       461.4|             493.4|       500.0|\n",
      "|                   562.8|                       590.4|             577.1|       580.0|\n",
      "|                   487.3|                       447.5|             431.4|       500.0|\n",
      "|                   427.1|                       478.2|             458.9|       540.0|\n",
      "|                   465.5|                       507.4|             455.1|       610.0|\n",
      "|                   705.0|                       622.6|             645.1|       700.0|\n",
      "|                   485.6|                       495.9|             536.0|       540.0|\n",
      "|                   518.9|                       561.5|             555.0|       560.0|\n",
      "|                   542.2|                       461.6|             442.9|       420.0|\n",
      "|                   434.5|                       370.9|             411.3|       440.0|\n",
      "|                   362.4|                       514.8|             481.8|       460.0|\n",
      "|                   535.4|                       526.2|             454.4|       880.0|\n",
      "|                   471.6|                       353.9|             527.0|       920.0|\n",
      "|                   383.7|                       453.6|             487.2|       400.0|\n",
      "|                   510.2|                       597.1|             632.3|       440.0|\n",
      "|                   655.8|                       603.1|             735.7|       940.0|\n",
      "|                   460.1|                       487.7|             470.3|       600.0|\n",
      "|                   377.4|                       483.2|             355.8|       480.0|\n",
      "|                   517.1|                       537.7|             455.9|       520.0|\n",
      "|                   475.0|                       507.3|             401.4|       520.0|\n",
      "+------------------------+----------------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NOTA_CH_CIENCIAS_HUMANAS', 'float'),\n",
       " ('NOTA_LC_LINGUAGENS_E_CODIGOS', 'float'),\n",
       " ('NOTA_MT_MATEMATICA', 'float'),\n",
       " ('NOTA_REDACAO', 'float')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the relevant columns\n",
    "selected_cols = [\"NOTA_CH_CIENCIAS_HUMANAS\", \"NOTA_LC_LINGUAGENS_E_CODIGOS\", \"NOTA_MT_MATEMATICA\", \"NOTA_REDACAO\"]\n",
    "df = df.select(*selected_cols)\n",
    "\n",
    "# filling nulls\n",
    "for my_col in selected_cols:\n",
    "    print('col:',my_col)\n",
    "    # Calculate the mean value for the column\n",
    "    mean_val = df.agg({my_col: \"mean\"}).collect()[0][0]\n",
    "    mean_val = round(mean_val,1)\n",
    "    # Fill missing values with the mean\n",
    "    df = df.na.fill(mean_val, [my_col])\n",
    "    df = df.withColumn(my_col, df[my_col].cast('float'))\n",
    "\n",
    "#rmv outliers\n",
    "for my_col in selected_cols:\n",
    "    # Calculate values used for outlier filtering\n",
    "    mean_val = df.agg({my_col: \"mean\"}).collect()[0][0]\n",
    "    stddev_val = df.agg({my_col: \"stddev\"}).collect()[0][0]\n",
    "\n",
    "    # Create three standard deviation (μ ± 3σ) lower and upper bounds for data\n",
    "    low_bound = mean_val - (3 * stddev_val)\n",
    "    hi_bound = mean_val + (3 * stddev_val)\n",
    "\n",
    "    # Filter the data to fit between the lower and upper bounds\n",
    "    df = df.where((df[my_col] < hi_bound) & (df[my_col] > low_bound))\n",
    "\n",
    "df.show()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "\n",
    "# Specify the path of the saved Random Forest model\n",
    "model_path = \"models/nota_ch_ciencias_humanas/random_forest\"\n",
    "\n",
    "# Load the Random Forest model from the specified path\n",
    "rf_model = RandomForestRegressionModel.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Output column features already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m assembler \u001b[39m=\u001b[39m VectorAssembler(inputCols\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mNOTA_LC_LINGUAGENS_E_CODIGOS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNOTA_MT_MATEMATICA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNOTA_REDACAO\u001b[39m\u001b[39m\"\u001b[39m], outputCol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Apply the VectorAssembler to transform the DataFrame\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[39m=\u001b[39m assembler\u001b[39m.\u001b[39;49mtransform(df)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Make predictions using the loaded Random Forest model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mtransform(df)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(dataset)\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/ml/wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 398\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mtransform(dataset\u001b[39m.\u001b[39;49m_jdf), dataset\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Output column features already exists."
     ]
    }
   ],
   "source": [
    "# Create a VectorAssembler to assemble the features\n",
    "assembler = VectorAssembler(inputCols=[\"NOTA_LC_LINGUAGENS_E_CODIGOS\", \"NOTA_MT_MATEMATICA\", \"NOTA_REDACAO\"], outputCol=\"features\")\n",
    "\n",
    "# Apply the VectorAssembler to transform the DataFrame\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Make predictions using the loaded Random Forest model\n",
    "predictions = rf_model.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------------------------+------------------+------------+--------------------+------------------+\n",
      "|NOTA_CH_CIENCIAS_HUMANAS|NOTA_LC_LINGUAGENS_E_CODIGOS|NOTA_MT_MATEMATICA|NOTA_REDACAO|            features|        prediction|\n",
      "+------------------------+----------------------------+------------------+------------+--------------------+------------------+\n",
      "|                   385.4|                       461.4|             493.4|       500.0|[461.399993896484...|448.11820412149837|\n",
      "|                   562.8|                       590.4|             577.1|       580.0|[590.400024414062...| 518.5185769791453|\n",
      "|                   487.3|                       447.5|             431.4|       500.0|[447.5,431.399993...|430.94040639160204|\n",
      "|                   427.1|                       478.2|             458.9|       540.0|[478.200012207031...|  446.670221071543|\n",
      "|                   465.5|                       507.4|             455.1|       610.0|[507.399993896484...|  452.703942684082|\n",
      "|                   705.0|                       622.6|             645.1|       700.0|[622.599975585937...| 556.3317954835563|\n",
      "|                   485.6|                       495.9|             536.0|       540.0|[495.899993896484...| 462.2601308898008|\n",
      "|                   518.9|                       561.5|             555.0|       560.0| [561.5,555.0,560.0]|503.40600167100354|\n",
      "|                   542.2|                       461.6|             442.9|       420.0|[461.600006103515...|435.03874995804546|\n",
      "|                   434.5|                       370.9|             411.3|       440.0|[370.899993896484...| 425.0362786947635|\n",
      "|                   362.4|                       514.8|             481.8|       460.0|[514.799987792968...|457.73938169370814|\n",
      "|                   535.4|                       526.2|             454.4|       880.0|[526.200012207031...| 486.0111610397486|\n",
      "|                   471.6|                       353.9|             527.0|       920.0|[353.899993896484...|467.48778828844263|\n",
      "|                   383.7|                       453.6|             487.2|       400.0|[453.600006103515...| 447.6571571870653|\n",
      "|                   510.2|                       597.1|             632.3|       440.0|[597.099975585937...| 545.0332561776281|\n",
      "|                   655.8|                       603.1|             735.7|       940.0|[603.099975585937...| 611.5333943851999|\n",
      "|                   460.1|                       487.7|             470.3|       600.0|[487.700012207031...| 450.6436167961857|\n",
      "|                   377.4|                       483.2|             355.8|       480.0|[483.200012207031...|435.93798093614504|\n",
      "|                   517.1|                       537.7|             455.9|       520.0|[537.700012207031...| 468.2241403831996|\n",
      "|                   475.0|                       507.3|             401.4|       520.0|[507.299987792968...| 445.0014760318278|\n",
      "+------------------------+----------------------------+------------------+------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()\n",
    "\n",
    "# Get a sample from the joined_predictions DataFrame\n",
    "sample_predictions = predictions.sample(fraction=0.1, seed=42)\n",
    "sample_predictions.write.mode('overwrite').parquet('data_for_dashboards/models/prediction_score_nota_ch_ciencias_humanas.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
